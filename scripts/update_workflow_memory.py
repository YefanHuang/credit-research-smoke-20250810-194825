#!/usr/bin/env python3
"""
ğŸ§  å·¥ä½œæµè®°å¿†æ›´æ–°è„šæœ¬
è‡ªåŠ¨è¯»å–ä¸Šæ¬¡è¿è¡Œçš„é…ç½®å¹¶æ›´æ–°å·¥ä½œæµé»˜è®¤å€¼
"""

import os
import json
import re
from pathlib import Path

def load_memory_config(memory_file):
    """åŠ è½½è®°å¿†é…ç½®æ–‡ä»¶"""
    try:
        with open(memory_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return None

def update_workflow_defaults(workflow_file, memory_config, config_mapping):
    """æ›´æ–°å·¥ä½œæµæ–‡ä»¶ä¸­çš„é»˜è®¤å€¼"""
    if not memory_config:
        print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°è®°å¿†é…ç½®ï¼Œè·³è¿‡ {workflow_file}")
        return
    
    with open(workflow_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    updated = False
    for param_name, memory_key in config_mapping.items():
        if memory_key in memory_config:
            # æŸ¥æ‰¾å‚æ•°å®šä¹‰è¡Œ
            pattern = rf'(\s+{param_name}:\s*\n\s+description:.*?\n\s+required:.*?\n\s+default:\s*[\'"]).+?([\'"]\s*\n)'
            match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
            
            if match:
                new_value = memory_config[memory_key]
                new_content = content[:match.start()] + match.group(1) + str(new_value) + match.group(2) + content[match.end():]
                content = new_content
                updated = True
                print(f"  âœ… æ›´æ–° {param_name}: {new_value}")
    
    if updated:
        with open(workflow_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“ å·²æ›´æ–° {workflow_file}")
    else:
        print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯æ›´æ–°çš„å‚æ•°åœ¨ {workflow_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  å¼€å§‹æ›´æ–°å·¥ä½œæµè®°å¿†é…ç½®")
    print("=" * 50)
    
    # é…ç½®æ˜ å°„
    workflows_config = {
        '.github/workflows/simple-research.yml': {
            'memory_file': '.github/memory/simple_research_config.json',
            'mapping': {
                'search_query_template': 'last_search_query_template',
                'result_title_template': 'last_result_title_template', 
                'result_content_template': 'last_result_content_template',
                'search_domains': 'last_search_domains',
                'time_filter': 'last_time_filter',
                'llm_model': 'last_llm_model',
                'embedding_model': 'last_embedding_model'
            }
        },
            '.github/workflows/unified_search.yml': {
        'memory_file': '.github/memory/aggregated_analysis_config.json',
            'mapping': {
                'search_query_template': 'last_search_query_template',
                'result_title_template': 'last_result_title_template',
                'result_content_template': 'last_result_content_template', 
                'search_domains': 'last_search_domains',
                'time_filter': 'last_time_filter',
                'llm_model': 'last_llm_model',
                'embedding_model': 'last_embedding_model',
                'search_model': 'last_search_model',
                'enable_vectorization': 'last_enable_vectorization',
                'selection_count': 'last_selection_count'
            }
        }
    }
    
    for workflow_file, config in workflows_config.items():
        print(f"\nğŸ”„ å¤„ç†å·¥ä½œæµ: {workflow_file}")
        
        if not os.path.exists(workflow_file):
            print(f"âŒ å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨: {workflow_file}")
            continue
            
        memory_config = load_memory_config(config['memory_file'])
        
        if memory_config:
            print(f"ğŸ“– è¯»å–è®°å¿†é…ç½®: {config['memory_file']}")
            print(f"ğŸ“… ä¸Šæ¬¡æ›´æ–°: {memory_config.get('last_updated', 'æœªçŸ¥')}")
            update_workflow_defaults(workflow_file, memory_config, config['mapping'])
        else:
            print(f"âš ï¸ è®°å¿†æ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸå: {config['memory_file']}")
    
    print("\n" + "=" * 50)
    print("âœ… å·¥ä½œæµè®°å¿†æ›´æ–°å®Œæˆ")

if __name__ == "__main__":
    main()