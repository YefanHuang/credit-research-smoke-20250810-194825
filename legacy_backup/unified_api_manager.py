#!/usr/bin/env python3
"""
ç»Ÿä¸€APIç®¡ç†å™¨
æ•´åˆåƒé—®å’ŒDeepSeek APIæ”¯æŒï¼Œåƒé—®ä¸ºä¸»ï¼ŒDeepSeekä¸ºå¤‡é€‰
"""

import asyncio
import json
import hashlib
import urllib.request
import urllib.parse
import urllib.error
from typing import Dict, List, Any, Optional, Union
from datetime import datetime
from enum import Enum
import logging

# å¯¼å…¥æ¨¡å‹ä¸€è‡´æ€§ç®¡ç†å™¨
try:
    from .model_consistency_manager import consistency_manager, register_embedding_model
except ImportError:
    try:
        from model_consistency_manager import consistency_manager, register_embedding_model
    except ImportError:
        print("è­¦å‘Š: æ— æ³•å¯¼å…¥model_consistency_managerï¼Œå°†è·³è¿‡ä¸€è‡´æ€§æ£€æŸ¥")
        consistency_manager = None
        register_embedding_model = None

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ModelProvider(Enum):
    """æ¨¡å‹æä¾›å•†æšä¸¾"""
    QWEN = "qwen"
    # DEEPSEEK = "deepseek"  # å·²æ³¨é‡Šï¼Œä¸“æ³¨åƒé—®API
    AUTO = "auto"  # è‡ªåŠ¨é€‰æ‹©

class APIEndpoint(Enum):
    """APIç«¯ç‚¹æšä¸¾"""
    QWEN_CHAT = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
    QWEN_EMBEDDING = "https://dashscope.aliyuncs.com/api/v1/services/embeddings/text-embedding/text-embedding"
    # DEEPSEEK_CHAT = "https://api.deepseek.com/chat/completions"  # å·²æ³¨é‡Š
    # DEEPSEEK_EMBEDDING = "https://api.deepseek.com/embeddings"  # å·²æ³¨é‡Š

class UnifiedAPIManager:
    """ç»Ÿä¸€APIç®¡ç†å™¨"""
    
    def __init__(self, api_config):
        """
        åˆå§‹åŒ–ç»Ÿä¸€APIç®¡ç†å™¨
        
        Args:
            api_config: APIConfigå®ä¾‹ï¼ŒåŒ…å«æ¨¡å‹æ³¨å†Œè¡¨
        """
        self.api_config = api_config
        self.model_registry = api_config.model_registry
        
        # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åˆ«å
        self.current_chat_model = api_config.default_chat_model
        self.current_embedding_model = api_config.default_embedding_model
        
        # APIè°ƒç”¨ç»Ÿè®¡ - åŠ¨æ€æ„å»ºåŸºäºå¯ç”¨æä¾›å•†
        self.api_stats = {}
        for provider in self.api_config.get_available_providers().keys():
            if provider != "perplexity":  # Perplexityæ˜¯æœç´¢APIï¼Œä¸åœ¨è¿™é‡Œç»Ÿè®¡
                self.api_stats[provider] = {"calls": 0, "success": 0, "errors": 0}
        
        # æ¨¡å‹ä¸€è‡´æ€§å“ˆå¸Œ
        self.consistency_hash = self._generate_consistency_hash()
    
    def _generate_consistency_hash(self) -> str:
        """ç”Ÿæˆæ¨¡å‹ä¸€è‡´æ€§å“ˆå¸Œ"""
        config_str = json.dumps({
            "qwen_model": self.model_configs[ModelProvider.QWEN]["embedding_model"],
            "current_provider": self.current_provider.value,
            "timestamp": datetime.now().isoformat()[:10]  # åªä½¿ç”¨æ—¥æœŸéƒ¨åˆ†
        }, sort_keys=True)
        
        return hashlib.md5(config_str.encode()).hexdigest()[:8]
    
    async def chat_completion(self, 
                            messages: List[Dict[str, str]], 
                            provider: ModelProvider = None,
                            **kwargs) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„èŠå¤©å®Œæˆæ¥å£
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            provider: æŒ‡å®šæä¾›å•†ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰æä¾›å•†
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            APIå“åº”ç»“æœ
        """
        if provider is None:
            provider = self.current_provider
        
        if provider == ModelProvider.AUTO:
            # è‡ªåŠ¨é€‰æ‹©ï¼šå…ˆå°è¯•åƒé—®ï¼Œå¤±è´¥åˆ™ä½¿ç”¨DeepSeek
            try:
                return await self._call_chat_api(ModelProvider.QWEN, messages, **kwargs)
            except Exception as e:
                logger.warning(f"åƒé—®APIè°ƒç”¨å¤±è´¥ï¼Œåˆ‡æ¢åˆ°DeepSeek: {e}")
                if self.deepseek_api_key:
                    return await self._call_chat_api(ModelProvider.DEEPSEEK, messages, **kwargs)
                else:
                    raise Exception("åƒé—®APIå¤±è´¥ä¸”æœªé…ç½®DeepSeek APIå¯†é’¥")
        else:
            return await self._call_chat_api(provider, messages, **kwargs)
    
    async def _call_chat_api(self, 
                           provider: ModelProvider, 
                           messages: List[Dict[str, str]], 
                           **kwargs) -> Dict[str, Any]:
        """è°ƒç”¨èŠå¤©API"""
        config = self.model_configs[provider]
        self.api_stats[provider]["calls"] += 1
        
        try:
            if provider == ModelProvider.QWEN:
                # åƒé—®APIæ ¼å¼
                payload = {
                    "model": config["chat_model"],
                    "input": {
                        "messages": messages
                    },
                    "parameters": {
                        "temperature": kwargs.get("temperature", 0.7),
                        "top_p": kwargs.get("top_p", 0.8),
                        "max_tokens": kwargs.get("max_tokens", 2000)
                    }
                }
            else:
                # DeepSeek APIæ ¼å¼ï¼ˆå…¼å®¹OpenAIï¼‰
                payload = {
                    "model": config["chat_model"],
                    "messages": messages,
                    "temperature": kwargs.get("temperature", 0.7),
                    "top_p": kwargs.get("top_p", 0.8),
                    "max_tokens": kwargs.get("max_tokens", 2000)
                }
            
            # ä½¿ç”¨urllibè¿›è¡ŒåŒæ­¥HTTPè¯·æ±‚ï¼ˆåœ¨å¼‚æ­¥å‡½æ•°ä¸­ï¼‰
            request_data = json.dumps(payload).encode('utf-8')
            req = urllib.request.Request(
                config["chat_endpoint"],
                data=request_data,
                headers=config["headers"]
            )
            
            try:
                with urllib.request.urlopen(req, timeout=60) as response:
                    if response.status == 200:
                        result_data = response.read().decode('utf-8')
                        result = json.loads(result_data)
                        self.api_stats[provider]["success"] += 1
                        
                        # ç»Ÿä¸€å“åº”æ ¼å¼
                        if provider == ModelProvider.QWEN:
                            content = result["output"]["text"]
                        else:
                            content = result["choices"][0]["message"]["content"]
                        
                        return {
                            "content": content,
                            "provider": provider.value,
                            "model": config["chat_model"],
                            "consistency_hash": self.consistency_hash,
                            "success": True
                        }
                    else:
                        error_text = response.read().decode('utf-8')
                        raise Exception(f"APIè¿”å›é”™è¯¯ {response.status}: {error_text}")
            except urllib.error.HTTPError as e:
                error_text = e.read().decode('utf-8') if hasattr(e, 'read') else str(e)
                raise Exception(f"HTTPé”™è¯¯ {e.code}: {error_text}")
            except urllib.error.URLError as e:
                raise Exception(f"ç½‘ç»œé”™è¯¯: {e.reason}")
                        
        except Exception as e:
            self.api_stats[provider]["errors"] += 1
            logger.error(f"{provider.value} èŠå¤©APIè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    async def create_embeddings(self, 
                              texts: List[str], 
                              model_alias: str = None) -> Dict[str, Any]:
        """
        åˆ›å»ºåµŒå…¥å‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            model_alias: æŒ‡å®šçš„æ¨¡å‹åˆ«åï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤embeddingæ¨¡å‹
            
        Returns:
            åµŒå…¥å‘é‡ç»“æœ
        """
        if model_alias is None:
            model_alias = self.current_embedding_model
            
        # è·å–æ¨¡å‹é…ç½®
        model_config = self.model_registry.get_model(model_alias)
        if not model_config:
            raise ValueError(f"æ¨¡å‹ {model_alias} æœªæ‰¾åˆ°åœ¨æ³¨å†Œè¡¨ä¸­")
        
        if model_config.model_type != "embedding":
            raise ValueError(f"æ¨¡å‹ {model_alias} ä¸æ˜¯å‘é‡åŒ–æ¨¡å‹")
            
        # æ³¨å†Œæ¨¡å‹åˆ°ä¸€è‡´æ€§ç®¡ç†å™¨
        try:
            from .model_consistency_manager import register_embedding_model
            model_hash = register_embedding_model(
                provider=model_config.provider,
                model_name=model_config.model_id,
                api_version="1.0",
                dimension=1536,  # æ ¹æ®æ¨¡å‹å®é™…ç»´åº¦è°ƒæ•´
                max_tokens=model_config.max_tokens
            )
        except ImportError:
            model_hash = "no_consistency_manager"
        
        try:
            result = await self._call_embedding_api(model_config, texts)
            result['model_consistency_hash'] = model_hash
            result['model_alias'] = model_alias
            return result
        except Exception as e:
            print(f"âŒ {model_alias}å‘é‡åŒ–å¤±è´¥: {e}")
            # å°è¯•åˆ‡æ¢åˆ°åŒç±»å‹çš„å…¶ä»–æ¨¡å‹
            fallback_models = self.model_registry.get_models_by_type("embedding")
            for alias, config in fallback_models.items():
                if alias != model_alias and config.api_key:
                    print(f"ğŸ”„ å°è¯•åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹: {alias}")
                    return await self.create_embeddings(texts, alias)
            raise
    
    async def _call_embedding_api(self, 
                                model_config, 
                                texts: List[str]) -> Dict[str, Any]:
        """è°ƒç”¨åµŒå…¥API"""
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        provider = model_config.provider
        if provider in self.api_stats:
            self.api_stats[provider]["calls"] += 1
        
        try:
            # æ ¹æ®æä¾›å•†æ„å»ºè¯·æ±‚
            if provider == "qwen":
                # åƒé—®åµŒå…¥APIæ ¼å¼
                payload = {
                    "model": model_config.model_id,
                    "input": {
                        "texts": texts
                    }
                }
            elif provider == "claude":
                # Claude æš‚ä¸æ”¯æŒ embeddingï¼Œè¿™é‡Œæ˜¯ç¤ºä¾‹
                payload = {
                    "model": model_config.model_id,
                    "input": texts
                }
            elif provider == "openai":
                # OpenAI æ ¼å¼
                payload = {
                    "model": model_config.model_id,
                    "input": texts
                }
            else:
                # é€šç”¨æ ¼å¼
                payload = {
                    "model": model_config.model_id,
                    "input": texts
                }
            
            # æ„å»ºè¯·æ±‚å¤´
            headers = {
                "Authorization": f"Bearer {model_config.api_key}",
                "Content-Type": "application/json"
            }
            headers.update(model_config.custom_headers)
            
            # ä½¿ç”¨urllibè¿›è¡ŒåŒæ­¥HTTPè¯·æ±‚
            request_data = json.dumps(payload).encode('utf-8')
            req = urllib.request.Request(
                model_config.base_url,
                data=request_data,
                headers=headers
            )
            
            try:
                with urllib.request.urlopen(req, timeout=120) as response:
                    if response.status == 200:
                        result_data = response.read().decode('utf-8')
                        result = json.loads(result_data)
                        if provider in self.api_stats:
                            self.api_stats[provider]["success"] += 1
                        
                        # ç»Ÿä¸€å“åº”æ ¼å¼
                        if provider == "qwen":
                            embeddings = [item["embedding"] for item in result["output"]["embeddings"]]
                        elif provider == "openai":
                            embeddings = [item["embedding"] for item in result["data"]]
                        else:
                            # é€šç”¨æ ¼å¼ï¼Œå‡è®¾å’ŒOpenAIå…¼å®¹
                            embeddings = [item["embedding"] for item in result["data"]]
                        
                        return {
                            "embeddings": embeddings,
                            "provider": provider,
                            "model": model_config.model_id,
                            "embedding_count": len(embeddings),
                            "success": True
                        }
                    else:
                        error_text = response.read().decode('utf-8')
                        raise Exception(f"APIè¿”å›é”™è¯¯ {response.status}: {error_text}")
            except urllib.error.HTTPError as e:
                error_text = e.read().decode('utf-8') if hasattr(e, 'read') else str(e)
                raise Exception(f"HTTPé”™è¯¯ {e.code}: {error_text}")
            except urllib.error.URLError as e:
                raise Exception(f"ç½‘ç»œé”™è¯¯: {e.reason}")
                        
        except Exception as e:
            if provider in self.api_stats:
                self.api_stats[provider]["errors"] += 1
            print(f"âŒ {provider} åµŒå…¥APIè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    async def intelligent_segmentation(self, 
                                     text: str, 
                                     max_chunk_size: int = 800,
                                     domain: str = "credit_research",
                                     provider: ModelProvider = None) -> List[str]:
        """
        æ™ºèƒ½æ–‡æœ¬åˆ‡åˆ†
        
        Args:
            text: å¾…åˆ‡åˆ†æ–‡æœ¬
            max_chunk_size: æœ€å¤§å—å¤§å°
            domain: é¢†åŸŸç±»å‹
            provider: æŒ‡å®šæä¾›å•†
            
        Returns:
            åˆ‡åˆ†åçš„æ–‡æœ¬å—åˆ—è¡¨
        """
        
        # æ„å»ºé¢†åŸŸç‰¹å®šçš„åˆ‡åˆ†æç¤º
        domain_prompts = {
            "credit_research": """
è¯·å°†ä»¥ä¸‹å¾ä¿¡ç ”ç©¶æ–‡æœ¬æŒ‰ç…§è¯­ä¹‰å®Œæ•´æ€§è¿›è¡Œæ™ºèƒ½åˆ‡åˆ†ï¼Œè¦æ±‚ï¼š

1. ä¿æŒè¯­ä¹‰å®Œæ•´æ€§ï¼Œä¸åœ¨å¥å­ä¸­é—´åˆ‡æ–­
2. æ¯ä¸ªæ–‡æœ¬å—ä¿æŒä¸»é¢˜ä¸€è‡´æ€§
3. ä¼˜å…ˆåœ¨æ®µè½ã€æ ‡é¢˜ã€åˆ—è¡¨ç­‰ç»“æ„æ€§æ ‡è®°å¤„åˆ‡åˆ†
4. æ¯å—å¤§å°æ§åˆ¶åœ¨{max_chunk_size}å­—ç¬¦ä»¥å†…
5. ä¿ç•™é‡è¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯

è¯·è¿”å›JSONæ ¼å¼çš„åˆ‡åˆ†ç»“æœï¼Œæ ¼å¼ä¸ºï¼š
{{"chunks": ["æ–‡æœ¬å—1", "æ–‡æœ¬å—2", ...]}}

å¾…åˆ‡åˆ†æ–‡æœ¬ï¼š
{text}
""",
            "general": """
è¯·å°†ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œæ™ºèƒ½åˆ‡åˆ†ï¼Œæ¯å—ä¸è¶…è¿‡{max_chunk_size}å­—ç¬¦ï¼Œ
ä¿æŒè¯­ä¹‰å®Œæ•´æ€§ï¼Œè¿”å›JSONæ ¼å¼ï¼š{{"chunks": ["æ–‡æœ¬å—1", "æ–‡æœ¬å—2", ...]}}

æ–‡æœ¬ï¼š
{text}
"""
        }
        
        prompt_template = domain_prompts.get(domain, domain_prompts["general"])
        prompt = prompt_template.format(max_chunk_size=max_chunk_size, text=text)
        
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ‡åˆ†åŠ©æ‰‹ï¼Œæ“…é•¿æŒ‰ç…§è¯­ä¹‰å®Œæ•´æ€§è¿›è¡Œæ–‡æœ¬åˆ‡åˆ†ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ]
        
        try:
            result = await self.chat_completion(messages, provider, temperature=0.1)
            
            # è§£æJSONç»“æœ
            import re
            json_match = re.search(r'\{.*"chunks".*\}', result["content"], re.DOTALL)
            if json_match:
                chunks_data = json.loads(json_match.group())
                chunks = chunks_data.get("chunks", [])
                
                # éªŒè¯å’Œæ¸…ç†åˆ‡åˆ†ç»“æœ
                valid_chunks = []
                for chunk in chunks:
                    if isinstance(chunk, str) and len(chunk.strip()) > 10:
                        valid_chunks.append(chunk.strip())
                
                return valid_chunks if valid_chunks else self._fallback_segmentation(text, max_chunk_size)
            else:
                logger.warning("APIè¿”å›æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨å¤‡ç”¨åˆ‡åˆ†æ–¹æ³•")
                return self._fallback_segmentation(text, max_chunk_size)
                
        except Exception as e:
            logger.error(f"æ™ºèƒ½åˆ‡åˆ†å¤±è´¥: {e}")
            return self._fallback_segmentation(text, max_chunk_size)
    
    def _fallback_segmentation(self, text: str, max_chunk_size: int) -> List[str]:
        """å¤‡ç”¨åˆ‡åˆ†æ–¹æ³•"""
        chunks = []
        sentences = text.split('ã€‚')
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk + sentence) <= max_chunk_size:
                current_chunk += sentence + "ã€‚"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + "ã€‚"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return [chunk for chunk in chunks if len(chunk.strip()) > 10]
    
    def switch_provider(self, provider: ModelProvider) -> Dict[str, Any]:
        """
        åˆ‡æ¢APIæä¾›å•†
        
        Args:
            provider: æ–°çš„æä¾›å•†
            
        Returns:
            åˆ‡æ¢ç»“æœ
        """
        old_provider = self.current_provider
        
        if provider == ModelProvider.DEEPSEEK and not self.deepseek_api_key:
            raise ValueError("æœªé…ç½®DeepSeek APIå¯†é’¥ï¼Œæ— æ³•åˆ‡æ¢")
        
        self.current_provider = provider
        self.consistency_hash = self._generate_consistency_hash()
        
        logger.info(f"APIæä¾›å•†å·²ä» {old_provider.value} åˆ‡æ¢åˆ° {provider.value}")
        
        return {
            "old_provider": old_provider.value,
            "new_provider": provider.value,
            "consistency_hash": self.consistency_hash,
            "switch_time": datetime.now().isoformat()
        }
    
    def get_api_statistics(self) -> Dict[str, Any]:
        """è·å–APIè°ƒç”¨ç»Ÿè®¡"""
        stats = {}
        for provider, data in self.api_stats.items():
            total_calls = data["calls"]
            success_rate = (data["success"] / total_calls * 100) if total_calls > 0 else 0
            
            stats[provider.value] = {
                "total_calls": total_calls,
                "successful_calls": data["success"],
                "failed_calls": data["errors"],
                "success_rate": round(success_rate, 2)
            }
        
        return {
            "current_provider": self.current_provider.value,
            "consistency_hash": self.consistency_hash,
            "statistics": stats,
            "generated_at": datetime.now().isoformat()
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {
            "qwen": {"available": False, "response_time": None, "error": None},
            "deepseek": {"available": False, "response_time": None, "error": None}
        }
        
        # æµ‹è¯•åƒé—®API
        try:
            start_time = datetime.now()
            await self.chat_completion([{"role": "user", "content": "Hello"}], ModelProvider.QWEN)
            response_time = (datetime.now() - start_time).total_seconds()
            health_status["qwen"] = {"available": True, "response_time": response_time, "error": None}
        except Exception as e:
            health_status["qwen"]["error"] = str(e)
        
        # æµ‹è¯•DeepSeek APIï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if self.deepseek_api_key:
            try:
                start_time = datetime.now()
                await self.chat_completion([{"role": "user", "content": "Hello"}], ModelProvider.DEEPSEEK)
                response_time = (datetime.now() - start_time).total_seconds()
                health_status["deepseek"] = {"available": True, "response_time": response_time, "error": None}
            except Exception as e:
                health_status["deepseek"]["error"] = str(e)
        else:
            health_status["deepseek"]["error"] = "APIå¯†é’¥æœªé…ç½®"
        
        return {
            "current_provider": self.current_provider.value,
            "health_status": health_status,
            "check_time": datetime.now().isoformat()
        }

# ä½¿ç”¨ç¤ºä¾‹
async def demo_unified_api():
    """æ¼”ç¤ºç»Ÿä¸€APIç®¡ç†å™¨"""
    
    # åˆå§‹åŒ–ï¼ˆè¿™é‡Œä½¿ç”¨æ¨¡æ‹Ÿçš„APIå¯†é’¥ï¼‰
    api_manager = UnifiedAPIManager(
        qwen_api_key="mock_qwen_key",
        deepseek_api_key="mock_deepseek_key"  # å¯é€‰
    )
    
    print("ğŸ¯ ç»Ÿä¸€APIç®¡ç†å™¨æ¼”ç¤º")
    print("=" * 50)
    
    # æ¼”ç¤ºèŠå¤©å®Œæˆ
    print("ğŸ’¬ èŠå¤©å®Œæˆæµ‹è¯•:")
    try:
        messages = [{"role": "user", "content": "è¯·ä»‹ç»å¾ä¿¡è¡Œä¸šçš„å‘å±•è¶‹åŠ¿"}]
        result = await api_manager.chat_completion(messages)
        print(f"   æä¾›å•†: {result['provider']}")
        print(f"   æ¨¡å‹: {result['model']}")
        print(f"   ä¸€è‡´æ€§å“ˆå¸Œ: {result['consistency_hash']}")
        print(f"   å“åº”é¢„è§ˆ: {result['content'][:100]}...")
    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    print()
    
    # æ¼”ç¤ºæ™ºèƒ½åˆ‡åˆ†
    print("âœ‚ï¸ æ™ºèƒ½æ–‡æœ¬åˆ‡åˆ†æµ‹è¯•:")
    test_text = "å¾ä¿¡è¡Œä¸šæ˜¯é‡‘èä½“ç³»çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚éšç€æ•°å­—åŒ–è½¬å‹çš„æ¨è¿›ï¼Œå¾ä¿¡æŠ€æœ¯ä¸æ–­åˆ›æ–°ã€‚äººå·¥æ™ºèƒ½åœ¨é£é™©è¯„ä¼°ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚"
    try:
        chunks = await api_manager.intelligent_segmentation(test_text, max_chunk_size=50)
        print(f"   åŸæ–‡é•¿åº¦: {len(test_text)} å­—ç¬¦")
        print(f"   åˆ‡åˆ†å—æ•°: {len(chunks)}")
        for i, chunk in enumerate(chunks, 1):
            print(f"   å—{i}: {chunk}")
    except Exception as e:
        print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    print()
    
    # æ¼”ç¤ºAPIç»Ÿè®¡
    print("ğŸ“Š APIè°ƒç”¨ç»Ÿè®¡:")
    stats = api_manager.get_api_statistics()
    print(f"   å½“å‰æä¾›å•†: {stats['current_provider']}")
    print(f"   ä¸€è‡´æ€§å“ˆå¸Œ: {stats['consistency_hash']}")
    for provider, data in stats['statistics'].items():
        print(f"   {provider}: {data}")

if __name__ == "__main__":
    print("ğŸ’¡ æ³¨æ„ï¼šè¿™æ˜¯æ¼”ç¤ºæ¨¡å¼ï¼Œä½¿ç”¨æ¨¡æ‹ŸAPIå¯†é’¥")
    print("å®é™…ä½¿ç”¨æ—¶è¯·é…ç½®çœŸå®çš„APIå¯†é’¥")
    print()
    
    # asyncio.run(demo_unified_api())