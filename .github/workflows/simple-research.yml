name: ğŸ“Š Simplified Research Automation

on:
  workflow_dispatch:
    inputs:
      search_topics:
        description: 'Research topics (comma-separated)'
        required: true
        default: 'credit risk management,ESG rating'
      
      email_recipients:
        description: 'Email recipients (comma-separated)'
        required: true
        default: 'admin@example.com'
        
      sender_name:
        description: 'Custom sender name'
        required: false
        default: 'CreditResearch'
      
      time_filter:
        description: 'Search time range'
        required: false
        default: 'week'
        type: choice
        options:
          - 'day'     # Last 24 hours
          - 'week'    # Last 7 days
          - 'month'   # Last 30 days
          - 'year'    # Last 365 days
      
      llm_model:
        description: 'LLM model selection'
        required: false
        default: 'llm'
        type: choice
        options:
          - 'llm'           # Default LLM model
          - 'llm-claude'    # Claude model
          - 'llm-gpt'       # GPT model
      
      embedding_model:
        description: 'Embedding model selection'
        required: false
        default: 'embedding'
        type: choice
        options:
          - 'embedding'         # Default embedding model
          - 'embedding-openai'  # OpenAI embedding model
      
      search_query_template:
        description: 'Custom Perplexity search query template'
        required: false
        default: '{topic} research methodology policy analysis central bank regulator academic paper whitepaper NOT corporate homepage NOT about-us NOT company-profile NOT marketing'
        type: string
      
      result_title_template:
        description: 'Custom search result title template'
        required: false
        default: 'Credit Research Dynamics - {topic}'
        type: string
      
      result_content_template:
        description: 'Custom search result content template'
        required: false
        default: 'Latest research dynamics and market analysis on {topic}, including policy changes, technology developments, market trends and other important information.'
        type: string
      


env:
  PERPLEXITY_API_KEY: ${{ secrets.PERPLEXITY_API_KEY }}
  QWEN_API_KEY: ${{ secrets.QWEN_API_KEY }}
  CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
  SMTP_PORT: ${{ secrets.SMTP_PORT }}
  SMTP_USER: ${{ secrets.SMTP_USER }}
  SMTP_PASSWORD: ${{ secrets.SMTP_PASSWORD }}

jobs:
  simple-research:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
    - name: ğŸ“¥ æ£€å‡ºä»£ç 
      uses: actions/checkout@v4
    
    - name: ğŸ è®¾ç½®Pythonç¯å¢ƒ
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: ğŸ“¦ å®‰è£…ä¾èµ–
      run: |
        python -m pip install --upgrade pip
        pip install requests urllib3 aiofiles asyncio python-dotenv openai
    
    - name: ğŸ“ åˆ›å»ºæŠ¥å‘Šç›®å½•
      run: |
        mkdir -p reports
        echo "âœ… æŠ¥å‘Šç›®å½•å·²åˆ›å»º"
    
    - name: ğŸ¯ æ‰§è¡Œç®€åŒ–ç ”ç©¶æµç¨‹
      id: research
      run: |
        python3 << 'EOF'
        import asyncio
        import os
        import sys
        import json
        import smtplib
        from datetime import datetime
        from email.mime.text import MIMEText
        from email.mime.multipart import MIMEMultipart
        from email.utils import formataddr
        
        async def main():
            print("ğŸ¯ å¼€å§‹ç®€åŒ–ç ”ç©¶è‡ªåŠ¨åŒ–")
            print("=" * 50)
            
            # è·å–è¾“å…¥å‚æ•°
            topics_input = "${{ github.event.inputs.search_topics || 'ä¿¡ç”¨é£é™©ç®¡ç†,ESGè¯„çº§' }}"
            topics = [t.strip() for t in topics_input.split(',') if t.strip()]
            
            recipients_input = "${{ github.event.inputs.email_recipients || 'admin@example.com' }}"
            recipients = [r.strip() for r in recipients_input.split(',') if r.strip()]
            
            sender_name = "${{ github.event.inputs.sender_name || 'CreditResearch' }}"
            time_filter = "${{ github.event.inputs.time_filter || 'week' }}"
            llm_model = "${{ github.event.inputs.llm_model || 'llm' }}"
            embedding_model = "${{ github.event.inputs.embedding_model || 'embedding' }}"
            
            # è‡ªå®šä¹‰Promptæ¨¡æ¿å‚æ•°
            search_query_template = "${{ github.event.inputs.search_query_template || '{topic} research methodology policy analysis central bank regulator academic paper whitepaper NOT corporate homepage NOT about-us NOT company-profile NOT marketing' }}"
            result_title_template = "${{ github.event.inputs.result_title_template || 'Credit Research Dynamics - {topic}' }}"
            result_content_template = "${{ github.event.inputs.result_content_template || 'Latest research dynamics and market analysis on {topic}, including policy changes, technology developments, market trends and other important information.' }}"

            
            print(f"ğŸ” æœç´¢ä¸»é¢˜: {topics}")
            print(f"ğŸ“§ æ¥æ”¶è€…: {recipients}")
            print(f"â° æ—¶é—´èŒƒå›´: {time_filter}")
            print(f"ğŸ¤– LLMæ¨¡å‹: {llm_model}")
            print(f"ğŸ§  Embeddingæ¨¡å‹: {embedding_model}")
            print(f"ğŸ“ æœç´¢æŸ¥è¯¢æ¨¡æ¿: {search_query_template}")
            print(f"ğŸ·ï¸ ç»“æœæ ‡é¢˜æ¨¡æ¿: {result_title_template}")

            
            # ä¿å­˜å½“å‰é…ç½®ç”¨äºä¸‹æ¬¡é»˜è®¤å€¼ (è®°å¿†åŠŸèƒ½)
            config_memory = {
                "last_search_query_template": search_query_template,
                "last_result_title_template": result_title_template,
                "last_result_content_template": result_content_template,

                "last_time_filter": time_filter,
                "last_llm_model": llm_model,
                "last_embedding_model": embedding_model,
                "last_updated": "$(date '+%Y-%m-%d %H:%M:%S')"
            }
            
            # ä¿å­˜é…ç½®åˆ°æ–‡ä»¶
            import json
            os.makedirs('.github/memory', exist_ok=True)
            with open('.github/memory/simple_research_config.json', 'w', encoding='utf-8') as f:
                json.dump(config_memory, f, ensure_ascii=False, indent=2)
            print("ğŸ’¾ å·²ä¿å­˜å½“å‰é…ç½®ï¼Œä¸‹æ¬¡è¿è¡Œå°†ä½œä¸ºé»˜è®¤å€¼")
            
            try:
                # å¯¼å…¥ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨
                sys.path.append(os.path.join(os.getcwd(), 'oop'))
                from model_manager import call_search, call_embedding, call_llm, get_model_status
                from search_result_processor import SearchResultProcessor
                
                # æ£€æŸ¥æ¨¡å‹çŠ¶æ€
                print("\nğŸ”§ æ£€æŸ¥æ¨¡å‹çŠ¶æ€...")
                model_status = get_model_status()
                available_models = {k: v for k, v in model_status.items() if v["available"]}
                
                if not available_models:
                    print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
                    return False
                
                print("âœ… å¯ç”¨æ¨¡å‹:")
                for alias, info in available_models.items():
                    print(f"  â€¢ {alias}: {info['provider']}-{info['model_id']} ({info['type']})")
                
                # ç¬¬1æ­¥ï¼šæ™ºèƒ½æœç´¢ï¼ˆå¹¶å‘å¤„ç†ï¼‰
                print("\nğŸ“¡ ç¬¬1æ­¥ï¼šæ‰§è¡Œæ™ºèƒ½æœç´¢...")
                print(f"ğŸš€ å¼€å§‹å¹¶å‘æœç´¢ {len(topics)} ä¸ªä¸»é¢˜...")
                
                async def search_single_topic_simple(topic):
                    """å¼‚æ­¥æœç´¢å•ä¸ªä¸»é¢˜ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
                    print(f"ğŸ” æœç´¢ä¸»é¢˜: {topic}")
                    
                    try:
                        # ä½¿ç”¨è‡ªå®šä¹‰æœç´¢æŸ¥è¯¢æ¨¡æ¿
                        search_query = search_query_template.format(topic=topic)
                        search_response = await call_search(
                            query=search_query,
                            model_alias="search",
                            search_recency_filter=time_filter,
                            return_related_questions=True,
                            max_results=3
                        )
                        
                        if search_response.get('success'):
                            # æå–Perplexityçš„æœç´¢å†…å®¹å’Œå…ƒæ•°æ®
                            content = search_response.get('content', '')
                            raw_search_results = search_response.get('search_results', [])
                            related_questions = search_response.get('related_questions', [])
                            
                            # æ„å»ºåŒ…å«åŸå§‹é“¾æ¥çš„ç»“æœ
                            result_item = {
                                "title": result_title_template.format(topic=topic),
                                "content": content,
                                "topic": topic,
                                "source": "Perplexity AI",
                                "relevance_score": 0.9,
                                "perplexity_sources": raw_search_results,  # åŸå§‹æœç´¢æ¥æº
                                "related_questions": related_questions,   # ç›¸å…³é—®é¢˜
                                "search_query": search_query,
                                "time_filter": time_filter
                            }
                            
                            # å¦‚æœæœ‰æœç´¢æ¥æºï¼Œæå–ç¬¬ä¸€ä¸ªä½œä¸ºä¸»è¦é“¾æ¥
                            if raw_search_results and len(raw_search_results) > 0:
                                first_source = raw_search_results[0]
                                result_item["url"] = first_source.get("url", "")
                                result_item["source_title"] = first_source.get("title", "")
                            else:
                                result_item["url"] = ""
                                result_item["source_title"] = ""
                            
                            print(f"  âœ… æ‰¾åˆ° {len(raw_search_results)} ä¸ªåŸå§‹æ¥æº for {topic}")
                            return result_item
                        else:
                            print(f"  âš ï¸ æœç´¢å¤±è´¥ for {topic}: {search_response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            # æ·»åŠ æ¨¡æ‹Ÿç»“æœä½œä¸ºå¤‡ç”¨
                            mock_result = {
                                "title": result_title_template.format(topic=topic),
                                "content": result_content_template.format(topic=topic),
                                "url": "https://example.com/research",
                                "source": "å¤‡ç”¨æ•°æ®",
                                "relevance_score": 0.8,
                                "topic": topic
                            }
                            return mock_result
                    
                    except Exception as e:
                        print(f"  âŒ æœç´¢å¼‚å¸¸ for {topic}: {e}")
                        # æ·»åŠ é”™è¯¯å¤„ç†çš„æ¨¡æ‹Ÿç»“æœ
                        mock_result = {
                            "title": f"Backup Data - {topic}",
                            "content": f"Research information and analysis report related to {topic}.",
                            "url": "https://example.com/backup", 
                            "source": "Simulated Data",
                            "relevance_score": 0.7,
                            "topic": topic
                        }
                        return mock_result
                
                # æ‰§è¡Œæ‰€æœ‰æœç´¢ä»»åŠ¡å¹¶å‘
                import asyncio
                import time
                search_start_time = time.time()
                search_tasks = [search_single_topic_simple(topic) for topic in topics]
                search_results_list = await asyncio.gather(*search_tasks, return_exceptions=True)
                search_end_time = time.time()
                
                print(f"âš¡ å¹¶å‘æœç´¢å®Œæˆï¼Œè€—æ—¶ {search_end_time - search_start_time:.2f} ç§’")
                
                # å¤„ç†ç»“æœå’Œå¼‚å¸¸
                search_results = []
                for i, result in enumerate(search_results_list):
                    if isinstance(result, Exception):
                        print(f"  âŒ ä»»åŠ¡å¤±è´¥ for {topics[i]}: {result}")
                        # æ·»åŠ å¤‡ç”¨ç»“æœ
                        search_results.append({
                            "title": f"Error Fallback - {topics[i]}",
                            "content": f"æœç´¢ä»»åŠ¡å¤±è´¥: {topics[i]}",
                            "url": "https://example.com/error",
                            "source": "é”™è¯¯å¤‡ç”¨",
                            "relevance_score": 0.5,
                            "topic": topics[i]
                        })
                    else:
                        search_results.append(result)
                
                print(f"âœ… æœç´¢å®Œæˆï¼Œæ€»å…±æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
                
                # ç¬¬2æ­¥ï¼šé«˜çº§æ–‡æœ¬å¤„ç†å’Œå‘é‡åŒ¹é…
                print("\nğŸ§  ç¬¬2æ­¥ï¼šæ™ºèƒ½å¤„ç†æœç´¢ç»“æœ...")
                
                processor = SearchResultProcessor()
                
                # TODO: è¿™é‡Œå¯ä»¥åŠ è½½ChromaDBé›†åˆè¿›è¡Œå‘é‡åŒ¹é…
                # chromadb_collection = load_chromadb_collection()  # éœ€è¦å®ç°
                chromadb_collection = None  # æš‚æ—¶è®¾ä¸ºNone
                
                processing_result = await processor.process_search_results(
                    search_results=search_results,
                    chromadb_collection=chromadb_collection,
                    enable_summarization=True,
                    max_chunk_size=600,
                    max_summary_length=300
                )
                
                if processing_result.get("success"):
                    # ä½¿ç”¨å¤„ç†åçš„ç»“æœ
                    processed_results = processing_result.get("filtered_results", processing_result.get("processed_results", []))
                    print(f"âœ¨ æ™ºèƒ½å¤„ç†å®Œæˆ: {len(search_results)} â†’ {len(processed_results)} ä¸ªä¼˜åŒ–ç»“æœ")
                    print(f"   ğŸ“Š ç”Ÿæˆæ–‡æœ¬å—: {processing_result.get('total_chunks', 0)} ä¸ª")
                    print(f"   ğŸ§® å‘é‡åŒ–: {len(processing_result.get('vectors', []))} ä¸ªå‘é‡")
                    
                    # æ›´æ–°æœç´¢ç»“æœä¸ºå¤„ç†åçš„ç»“æœ
                    search_results = processed_results
                else:
                    print("âš ï¸ æ™ºèƒ½å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æœç´¢ç»“æœ")
                    errors = processing_result.get("errors", [])
                    for error in errors:
                        print(f"   âŒ {error}")
                
                # ç¬¬3æ­¥ï¼šç”Ÿæˆå¢å¼ºæŠ¥å‘Š
                print("\nğŸ“ ç¬¬3æ­¥ï¼šç”Ÿæˆå¢å¼ºç ”ç©¶æŠ¥å‘Š...")
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # ç®€åŒ–çš„æŠ¥å‘Šç”Ÿæˆ
                report_lines = [
                    "Credit Research Dynamics",
                    f"Time: {current_time}",
                    f"Research Topics: {', '.join(topics)}",
                    f"Time Range: {time_filter}",
                    f"Models Used: {llm_model}, {embedding_model}",
                    "",
                    "=== Research Results ===",
                    ""
                ]
                
                for i, result in enumerate(search_results, 1):
                    # ä½¿ç”¨å¤„ç†åçš„ç›¸å…³æ€§è¯„åˆ†
                    relevance = result.get('final_score', result.get('relevance_score', 0.8))
                    
                    # ä½¿ç”¨æ™ºèƒ½æ¦‚æ‹¬çš„å†…å®¹
                    content = result.get('processed_content', result.get('content', 'æ— å†…å®¹'))
                    
                    # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
                    processing_info = ""
                    if result.get('enhanced'):
                        vector_boost = result.get('vector_boost', 0)
                        matching_count = result.get('matching_count', 0)
                        chunk_count = result.get('chunk_count', 0)
                        processing_info = f"   ğŸ§  æ™ºèƒ½å¤„ç†: +{vector_boost:.3f}åˆ† | {matching_count}ä¸ªåŒ¹é… | {chunk_count}ä¸ªå—"
                    
                    report_lines.extend([
                        f"{i}. {result.get('title', 'æ— æ ‡é¢˜')}",
                        f"   ç›¸å…³æ€§: {relevance:.3f}",
                        f"   æ¥æº: {result.get('source', 'æœªçŸ¥')}",
                    ])
                    
                    # æ˜¾ç¤ºä¸»è¦é“¾æ¥
                    main_url = result.get('url', '')
                    if main_url:
                        source_title = result.get('source_title', 'åŸå§‹æ¥æº')
                        report_lines.append(f"   ğŸ”— ä¸»è¦é“¾æ¥: {main_url}")
                        if source_title:
                            report_lines.append(f"   ğŸ“„ æ¥æºæ ‡é¢˜: {source_title}")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰PerplexityåŸå§‹æ¥æº
                    perplexity_sources = result.get('perplexity_sources', [])
                    if perplexity_sources:
                        report_lines.append(f"   ğŸ“š å¼•ç”¨æ¥æº ({len(perplexity_sources)}ä¸ª):")
                        for j, source in enumerate(perplexity_sources[:5], 1):  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                            source_url = source.get('url', '')
                            source_title = source.get('title', 'æ— æ ‡é¢˜')
                            if source_url:
                                report_lines.append(f"      {j}. {source_title}")
                                report_lines.append(f"         ğŸŒ {source_url}")
                    
                    # æ˜¾ç¤ºç›¸å…³é—®é¢˜
                    related_questions = result.get('related_questions', [])
                    if related_questions:
                        report_lines.append(f"   ğŸ’¡ ç›¸å…³é—®é¢˜:")
                        for question in related_questions[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                            report_lines.append(f"      â€¢ {question}")
                    
                    if processing_info:
                        report_lines.append(processing_info)
                    
                    report_lines.extend([
                        "",
                        f"   ğŸ“ æ™ºèƒ½æ‘˜è¦:",
                        f"   {content}",
                        ""
                    ])
                
                report_lines.extend([
                    "=== Technical Information ===",
                    f"Processing Time: {current_time}",
                    f"Total Results: {len(search_results)}",
                    f"LLM Model: {llm_model}",
                    f"Embedding Model: {embedding_model}",
                    "",
                    "This report is generated by the Unified Model Manager"
                ])
                
                report_content = "\n".join(report_lines)
                
                # ä¿å­˜æŠ¥å‘Š
                report_filename = f"research_report_{timestamp}.txt"
                report_filepath = f"reports/{report_filename}"
                
                with open(report_filepath, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                
                print(f"ğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {report_filepath}")
                
                # ç¬¬3æ­¥ï¼šå‘é€é‚®ä»¶
                print("\nğŸ“§ ç¬¬3æ­¥ï¼šå‘é€é‚®ä»¶...")
                
                def send_email():
                    try:
                        # SMTPé…ç½®
                        smtp_server = os.getenv('SMTP_SERVER')
                        smtp_port = int(os.getenv('SMTP_PORT', '587'))
                        smtp_user = os.getenv('SMTP_USER')
                        smtp_password = os.getenv('SMTP_PASSWORD')
                        
                        if not all([smtp_server, smtp_user, smtp_password]):
                            print("âš ï¸ SMTPé…ç½®ä¸å®Œæ•´ï¼Œè·³è¿‡é‚®ä»¶å‘é€")
                            return True
                        
                        # åˆ›å»ºé‚®ä»¶
                        msg = MIMEMultipart()
                        msg['From'] = formataddr((sender_name, smtp_user))
                        msg['Subject'] = f"Credit Research Dynamics - {'/'.join(topics)} ({datetime.now().strftime('%Y-%m-%d')})"
                        
                        # é‚®ä»¶æ­£æ–‡
                        body_lines = [
                            "Credit Research Dynamics Report",
                            "",
                            f"Research Topics: {', '.join(topics)}",
                            f"Processing Time: {current_time}",
                            f"Result Count: {len(search_results)}",
                            "",
                            report_content,
                            "",
                            f"Report File: {report_filename}",
                            "Generated by: Unified Model Manager v2.0"
                        ]
                        body = "\n".join(body_lines)
                        
                        msg.attach(MIMEText(body, 'plain', 'utf-8'))
                        
                        # å‘é€é‚®ä»¶
                        print(f"ğŸ“¡ è¿æ¥SMTPæœåŠ¡å™¨: {smtp_server}:{smtp_port}")
                        
                        with smtplib.SMTP(smtp_server, smtp_port) as server:
                            server.starttls()
                            server.login(smtp_user, smtp_password)
                            
                            for recipient in recipients:
                                msg['To'] = recipient
                                server.send_message(msg)
                                print(f"âœ… é‚®ä»¶å·²å‘é€è‡³: {recipient}")
                                del msg['To']
                        
                        return True
                        
                    except Exception as e:
                        print(f"âš ï¸ é‚®ä»¶å‘é€é”™è¯¯: {e}")
                        print("ğŸ“ é‚®ä»¶å‘é€å¤±è´¥ä¸å½±å“ç ”ç©¶æµç¨‹å®Œæˆ")
                        return True  # ä¸å› é‚®ä»¶å¤±è´¥è€Œä¸­æ–­æµç¨‹
                
                email_success = send_email()
                
                # æœ€ç»ˆç»Ÿè®¡
                print(f"\nğŸ‰ ç®€åŒ–ç ”ç©¶è‡ªåŠ¨åŒ–å®Œæˆ!")
                print(f"ğŸ“‹ æŠ¥å‘Šæ–‡ä»¶: {report_filepath}")
                print(f"ğŸ“§ é‚®ä»¶çŠ¶æ€: {'âœ… æˆåŠŸ' if email_success else 'âš ï¸ å¤±è´¥'}")
                print(f"ğŸ” ç»“æœæ•°é‡: {len(search_results)}")
                print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {llm_model}/{embedding_model}")
                
                return True
                
            except ImportError as e:
                print(f"âŒ æ— æ³•å¯¼å…¥ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨: {e}")
                print("ğŸ“ è¯·ç¡®ä¿ oop/model_manager.py å­˜åœ¨ä¸”é…ç½®æ­£ç¡®")
                return False
                
            except Exception as e:
                print(f"âŒ ç ”ç©¶æµç¨‹å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return False
        
        # è¿è¡Œä¸»å‡½æ•°
        if __name__ == "__main__":
            success = asyncio.run(main())
            if not success:
                exit(1)
            else:
                print("\nâœ… ç®€åŒ–ç ”ç©¶è‡ªåŠ¨åŒ–æˆåŠŸå®Œæˆ!")
        EOF
    
    - name: ğŸ“¤ ä¸Šä¼ ç ”ç©¶æŠ¥å‘Š
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: research-reports
        path: reports/
        retention-days: 30
    
    - name: ğŸ¯ è¾“å‡ºæ‘˜è¦
      if: always()
      run: |
        echo "## ğŸ“Š Simplified Research Automation Summary" >> $GITHUB_STEP_SUMMARY
        echo "**Execution Time**: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "**Research Topics**: ${{ github.event.inputs.search_topics }}" >> $GITHUB_STEP_SUMMARY
        echo "**Time Range**: ${{ github.event.inputs.time_filter }}" >> $GITHUB_STEP_SUMMARY
        echo "**Models Used**: ${{ github.event.inputs.llm_model }}/${{ github.event.inputs.embedding_model }}" >> $GITHUB_STEP_SUMMARY
        
        if [ "${{ steps.research.outcome }}" = "success" ]; then
          echo "**Status**: âœ… Success" >> $GITHUB_STEP_SUMMARY
        else
          echo "**Status**: âŒ Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Key Features" >> $GITHUB_STEP_SUMMARY
        echo "- ğŸ¯ **Modern Architecture**: Fully utilizing Unified Model Manager" >> $GITHUB_STEP_SUMMARY
        echo "- ğŸ”§ **Smart Selection**: Support for LLM/Embedding model switching" >> $GITHUB_STEP_SUMMARY
        echo "- ğŸ“ **Streamlined Process**: Efficient research and report generation" >> $GITHUB_STEP_SUMMARY
        echo "- ğŸ“Š **Clear Output**: Structured reports and email notifications" >> $GITHUB_STEP_SUMMARY