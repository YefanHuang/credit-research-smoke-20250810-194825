"""
æœç´¢ç®¡ç†æ¨¡å—
"""

import json
from typing import List, Dict, Any, Optional
from datetime import datetime
from openai import OpenAI

class SearchManager:
    """æœç´¢ç®¡ç†å™¨"""
    
    def __init__(self, api_key: str):
        """
        åˆå§‹åŒ–æœç´¢ç®¡ç†å™¨
        
        Args:
            api_key: Perplexity APIå¯†é’¥
        """
        self.api_key = api_key
        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.perplexity.ai"
        )
        self.model_name = "sonar"  # ä½¿ç”¨ä¾¿å®œçš„sonaræ¨¡å‹
        
        # Credit rating focused search strategy
        self.credit_keywords = {
            "regulatory": ["Credit Rating Regulation", "Rating Agency Oversight", "Credit Rating Standards", "Rating Compliance", "Rating Policy"],
            "rating_agencies": ["S&P Global", "Moody's", "Fitch Ratings", "DBRS", "Japan Credit Rating Agency", "Rating and Investment Information"],
            "consumer_credit": ["TransUnion", "Equifax", "Experian", "CRIF", "Creditinfo", "Credit Bureau"],
            "national_bureaus": ["Federal Reserve", "European Central Bank", "Financial Services Agency", "SAMA", "RBI", "BCB", "SBS", "CNBV"],
            "rating_methodology": ["Credit Rating Process", "Rating Criteria", "Default Analysis", "Credit Assessment", "Rating Scale"]
        }
        
        self.authoritative_sources = [
            # International Organizations
            "World Bank", "IMF", "Bank for International Settlements", "European Banking Authority",
            # Rating Agencies
            "S&P Global Ratings", "Moody's Analytics", "Fitch Ratings", "DBRS Morningstar",
            # Consumer Credit Agencies
            "TransUnion", "Equifax", "Experian",
            # Research Institutions
            "Basel Committee", "IOSCO", "European Securities and Markets Authority"
        ]
    
    def search_topic(self, topic: str, time_filter: str = "week") -> Dict[str, Any]:
        """
        æœç´¢å•ä¸ªä¸»é¢˜
        
        Args:
            topic: æœç´¢ä¸»é¢˜
            time_filter: æ—¶é—´è¿‡æ»¤ ("week", "month", "year")
            
        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        try:
            # ç”Ÿæˆå¢å¼ºçš„æœç´¢æç¤º
            enhanced_prompt = self._create_enhanced_prompt(topic)
            
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {
                        "role": "system", 
                        "content": """You are a professional financial research assistant specializing in credit research and risk management. 
Your expertise covers:
- Chinese financial regulations and policies
- Credit scoring and risk assessment technologies  
- Financial technology innovations
- Data privacy and security in finance
- International best practices in credit industry

Provide accurate, up-to-date information with authoritative sources and detailed analysis."""
                    },
                    {
                        "role": "user", 
                        "content": enhanced_prompt
                    }
                ],
                extra_body={
                    "search_recency_filter": time_filter,
                    "return_citations": True,
                    "return_images": False,
                    "temperature": 0.2,
                    "top_p": 0.9,
                    "max_tokens": 4000
                }
            )
            
            content = response.choices[0].message.content
            
            return {
                "topic": topic,
                "search_query": topic,
                "time_filter": time_filter,
                "content": content,
                "model": self.model_name,
                "timestamp": datetime.now().isoformat(),
                "success": True
            }
            
        except Exception as e:
            print(f"âŒ æœç´¢ä¸»é¢˜ '{topic}' å¤±è´¥: {e}")
            return {
                "topic": topic,
                "search_query": topic,
                "time_filter": time_filter,
                "error": str(e),
                "content": None,
                "timestamp": datetime.now().isoformat(),
                "success": False
            }
    
    def search_multiple_topics(self, topics: List[str], time_filter: str = "week") -> List[Dict[str, Any]]:
        """
        æœç´¢å¤šä¸ªä¸»é¢˜
        
        Args:
            topics: ä¸»é¢˜åˆ—è¡¨
            time_filter: æ—¶é—´è¿‡æ»¤
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        results = []
        
        print(f"ğŸ” å¼€å§‹æœç´¢ {len(topics)} ä¸ªä¸»é¢˜...")
        
        for i, topic in enumerate(topics, 1):
            print(f"  [{i}/{len(topics)}] æœç´¢: {topic}")
            result = self.search_topic(topic, time_filter)
            results.append(result)
            
            if result["success"]:
                print(f"    âœ… æˆåŠŸ")
            else:
                print(f"    âŒ å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        return results
    
    def save_results(self, results: List[Dict[str, Any]], filepath: str = "data/perplexity_results.json"):
        """
        ä¿å­˜æœç´¢ç»“æœ
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            filepath: ä¿å­˜è·¯å¾„
        """
        import os
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ æœç´¢ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    
    def load_results(self, filepath: str = "data/perplexity_results.json") -> List[Dict[str, Any]]:
        """
        åŠ è½½æœç´¢ç»“æœ
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"âŒ æœªæ‰¾åˆ°æœç´¢ç»“æœæ–‡ä»¶: {filepath}")
            return []
        except Exception as e:
            print(f"âŒ åŠ è½½æœç´¢ç»“æœå¤±è´¥: {e}")
            return []
    
    def test_connection(self) -> bool:
        """æµ‹è¯•APIè¿æ¥"""
        try:
            test_result = self.search_topic("ä¿¡ç”¨è¯„çº§åŸºæœ¬æ¦‚å¿µ")
            
            if test_result["success"]:
                print("âœ… Perplexity API è¿æ¥æˆåŠŸ")
                print(f"ğŸ“ è¿”å›å†…å®¹é•¿åº¦: {len(test_result['content'])} å­—ç¬¦")
                print(f"ğŸ“„ å†…å®¹é¢„è§ˆ: {test_result['content'][:200]}...")
                return True
            else:
                print(f"âŒ Perplexity API è¿æ¥å¤±è´¥: {test_result.get('error')}")
                return False
                
        except Exception as e:
            print(f"âŒ Perplexity API è¿æ¥å¤±è´¥: {e}")
            return False
    
    def get_search_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        total_searches = len(results)
        successful_searches = sum(1 for r in results if r.get("success", False))
        failed_searches = total_searches - successful_searches
        
        total_content_length = sum(
            len(r.get("content", "")) for r in results if r.get("success", False)
        )
        
        return {
            "total_searches": total_searches,
            "successful_searches": successful_searches,
            "failed_searches": failed_searches,
            "success_rate": successful_searches / total_searches if total_searches > 0 else 0,
            "total_content_length": total_content_length,
            "average_content_length": total_content_length / successful_searches if successful_searches > 0 else 0
        }
    
    def _create_enhanced_prompt(self, topic: str) -> str:
        """
        åˆ›å»ºå¢å¼ºçš„æœç´¢æç¤ºè¯
        
        Args:
            topic: æœç´¢ä¸»é¢˜
            
        Returns:
            å¢å¼ºçš„æç¤ºè¯
        """
        # æå–ç›¸å…³å…³é”®è¯
        relevant_keywords = self._extract_relevant_keywords(topic)
        
        enhanced_prompt = f"Find recent research and analysis about {topic}. Include policy documents, research papers, and analytical reports from financial institutions, central banks, and regulatory bodies."
        
        return enhanced_prompt.strip()
    
    def _extract_relevant_keywords(self, topic: str) -> List[str]:
        """
        æå–ä¸ä¸»é¢˜ç›¸å…³çš„å…³é”®è¯
        
        Args:
            topic: æœç´¢ä¸»é¢˜
            
        Returns:
            ç›¸å…³å…³é”®è¯åˆ—è¡¨
        """
        topic_lower = topic.lower()
        relevant = []
        
        for category, keywords in self.credit_keywords.items():
            for keyword in keywords:
                if any(word in topic_lower for word in keyword.lower().split()):
                    relevant.extend(keywords[:3])  # å–å‰3ä¸ªç›¸å…³å…³é”®è¯
                    break
        
        # å»é‡å¹¶é™åˆ¶æ•°é‡
        return list(set(relevant))[:8] 