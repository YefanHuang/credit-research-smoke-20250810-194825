#!/usr/bin/env python3
"""
ğŸ¯ ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨ - å”¯ä¸€çš„æ¨¡å‹ç®¡ç†å…¥å£
è§£å†³8ä¸ªé‡å¤æ¨¡å—çš„æ··ä¹±å±€é¢ï¼Œå®ç°çœŸæ­£çš„ç»Ÿä¸€ç®¡ç†

æŠ½è±¡å±‚çº§:
- llm: å¤§è¯­è¨€æ¨¡å‹ (å¦‚Qwen-Turbo, Claude, GPT-4)  
- embedding: å‘é‡åŒ–æ¨¡å‹ (å¦‚text-embedding-v4)
- search: æœç´¢æ¨¡å‹ (å¦‚Perplexity)
"""

import os
import json
import asyncio
import urllib.request
import urllib.error
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass
from enum import Enum
from datetime import datetime

# å°è¯•å¯¼å…¥å¼‚æ­¥HTTPå®¢æˆ·ç«¯
try:
    import httpx
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False


class ModelType(Enum):
    """ç»Ÿä¸€æ¨¡å‹ç±»å‹æŠ½è±¡"""
    LLM = "llm"                    # å¤§è¯­è¨€æ¨¡å‹
    EMBEDDING = "embedding"         # å‘é‡åŒ–æ¨¡å‹  
    SEARCH = "search"              # æœç´¢æ¨¡å‹


class ModelStatus(Enum):
    """æ¨¡å‹çŠ¶æ€"""
    AVAILABLE = "available"
    UNAVAILABLE = "unavailable"
    ERROR = "error"


@dataclass
class ModelConfig:
    """ç»Ÿä¸€æ¨¡å‹é…ç½®"""
    alias: str                     # æ¨¡å‹åˆ«å (å¦‚ "llm", "embedding", "search")
    provider: str                  # æä¾›å•† (å¦‚ "qwen", "perplexity", "claude")
    model_id: str                  # å…·ä½“æ¨¡å‹ID (å¦‚ "qwen-turbo", "sonar-pro")
    model_type: ModelType          # æ¨¡å‹ç±»å‹
    api_key: str                   # APIå¯†é’¥
    base_url: str                  # APIç«¯ç‚¹
    max_tokens: int = 4000         # æœ€å¤§tokenæ•°
    temperature: float = 0.7       # æ¸©åº¦å‚æ•°
    headers: Dict[str, str] = None # è‡ªå®šä¹‰è¯·æ±‚å¤´
    
    def __post_init__(self):
        if self.headers is None:
            self.headers = {}


class UnifiedModelManager:
    """ğŸ¯ ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨ - ç³»ç»Ÿä¸­å”¯ä¸€çš„æ¨¡å‹ç®¡ç†å…¥å£"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨"""
        self.models: Dict[str, ModelConfig] = {}
        self.usage_stats: Dict[str, Dict] = {}
        self.token_usage: Dict[str, Dict] = {}
        
        # è‡ªåŠ¨æ³¨å†Œå¯ç”¨æ¨¡å‹
        self._register_default_models()
        
    def _register_default_models(self):
        """æ³¨å†Œé»˜è®¤æ¨¡å‹é…ç½®"""
        
        # ğŸ¤– å¤§è¯­è¨€æ¨¡å‹ (LLM)
        qwen_api_key = os.getenv('QWEN_API_KEY')
        if qwen_api_key:
            self.register_model(ModelConfig(
                alias="llm",
                provider="qwen", 
                model_id=os.getenv('DEFAULT_CHAT_MODEL', 'qwen-turbo'),
                model_type=ModelType.LLM,
                api_key=qwen_api_key,
                base_url="https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"
            ))
            
        # ğŸ§  å‘é‡åŒ–æ¨¡å‹ (EMBEDDING) 
        if qwen_api_key:
            self.register_model(ModelConfig(
                alias="embedding",
                provider="qwen",
                model_id="text-embedding-v2", 
                model_type=ModelType.EMBEDDING,
                api_key=qwen_api_key,
                base_url="https://dashscope.aliyuncs.com/api/v1/services/embeddings/text-embedding/text-embedding"
            ))
            
        # ğŸ” æœç´¢æ¨¡å‹ (SEARCH)
        perplexity_key = os.getenv('PERPLEXITY_API_KEY')
        if perplexity_key:
            self.register_model(ModelConfig(
                alias="search",
                provider="perplexity", 
                model_id="sonar-pro",
                model_type=ModelType.SEARCH,
                api_key=perplexity_key,
                base_url="https://api.perplexity.ai/chat/completions"
            ))
            
        # é¢„ç•™å…¶ä»–æ¨¡å‹
        self._register_optional_models()
    
    def _register_optional_models(self):
        """æ³¨å†Œå¯é€‰æ¨¡å‹"""
        
        # Claudeæ¨¡å‹
        claude_key = os.getenv('CLAUDE_API_KEY')
        if claude_key:
            self.register_model(ModelConfig(
                alias="llm-claude",
                provider="claude",
                model_id="claude-3-sonnet-20240229", 
                model_type=ModelType.LLM,
                api_key=claude_key,
                base_url="https://api.anthropic.com/v1/messages",
                headers={"anthropic-version": "2023-06-01"}
            ))
            
        # OpenAIæ¨¡å‹
        openai_key = os.getenv('OPENAI_API_KEY')
        if openai_key:
            self.register_model(ModelConfig(
                alias="llm-gpt",
                provider="openai",
                model_id="gpt-4-turbo-preview",
                model_type=ModelType.LLM, 
                api_key=openai_key,
                base_url="https://api.openai.com/v1/chat/completions"
            ))
            
            self.register_model(ModelConfig(
                alias="embedding-openai",
                provider="openai",
                model_id="text-embedding-3-large",
                model_type=ModelType.EMBEDDING,
                api_key=openai_key, 
                base_url="https://api.openai.com/v1/embeddings"
            ))
    
    def register_model(self, config: ModelConfig):
        """æ³¨å†Œæ–°æ¨¡å‹"""
        self.models[config.alias] = config
        self.usage_stats[config.alias] = {
            "calls": 0,
            "success": 0, 
            "errors": 0,
            "last_used": None
        }
        self.token_usage[config.alias] = {
            "input_tokens": 0,
            "output_tokens": 0,
            "total_tokens": 0
        }
        print(f"âœ… æ³¨å†Œæ¨¡å‹: {config.alias} ({config.provider}-{config.model_id})")
    
    def get_model(self, alias: str) -> Optional[ModelConfig]:
        """è·å–æ¨¡å‹é…ç½®"""
        return self.models.get(alias)
    
    def get_models_by_type(self, model_type: ModelType) -> Dict[str, ModelConfig]:
        """æ ¹æ®ç±»å‹è·å–æ¨¡å‹"""
        return {
            alias: config for alias, config in self.models.items()
            if config.model_type == model_type
        }
    
    def get_primary_model(self, model_type: ModelType) -> Optional[ModelConfig]:
        """è·å–ä¸»è¦æ¨¡å‹ï¼ˆæ— å‰ç¼€çš„åˆ«åï¼‰"""
        type_name = model_type.value
        return self.models.get(type_name)
    
    async def call_llm(self, 
                      prompt: str, 
                      model_alias: str = "llm",
                      **kwargs) -> Dict[str, Any]:
        """è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹"""
        config = self.get_model(model_alias)
        if not config or config.model_type != ModelType.LLM:
            raise ValueError(f"LLMæ¨¡å‹ {model_alias} ä¸å¯ç”¨")
            
        return await self._make_api_call(config, {
            "model": config.model_id,
            "messages": [{"role": "user", "content": prompt}],
            **kwargs
        })
    
    async def call_embedding(self, 
                           texts: List[str], 
                           model_alias: str = "embedding") -> Dict[str, Any]:
        """è°ƒç”¨å‘é‡åŒ–æ¨¡å‹"""
        config = self.get_model(model_alias)
        if not config or config.model_type != ModelType.EMBEDDING:
            raise ValueError(f"å‘é‡åŒ–æ¨¡å‹ {model_alias} ä¸å¯ç”¨")
            
        # æ ¹æ®æä¾›å•†æ„å»ºè¯·æ±‚
        if config.provider == "qwen":
            payload = {
                "model": config.model_id,
                "input": {"texts": texts}
            }
        elif config.provider == "openai":
            payload = {
                "model": config.model_id,
                "input": texts
            }
        else:
            payload = {
                "model": config.model_id, 
                "input": texts
            }
            
        result = await self._make_api_call(config, payload)
        
        # ç»Ÿä¸€å“åº”æ ¼å¼
        if config.provider == "qwen":
            embeddings = [item["embedding"] for item in result["output"]["embeddings"]]
        else:
            embeddings = [item["embedding"] for item in result["data"]]
            
        return {
            "embeddings": embeddings,
            "model": model_alias,
            "provider": config.provider,
            "success": True
        }
    
    async def call_search(self,
                         query: str,
                         model_alias: str = "search", 
                         **kwargs) -> Dict[str, Any]:
        """è°ƒç”¨æœç´¢æ¨¡å‹ - æ”¯æŒPerplexityç‰¹æœ‰å‚æ•°"""
        config = self.get_model(model_alias)
        if not config or config.model_type != ModelType.SEARCH:
            raise ValueError(f"æœç´¢æ¨¡å‹ {model_alias} ä¸å¯ç”¨")
            
        # æ„å»ºåŸºç¡€payload
        payload = {
            "model": config.model_id,
            "messages": [{"role": "user", "content": query}]
        }
        
        # å¤„ç†Perplexityç‰¹æœ‰å‚æ•°
        if config.provider == "perplexity":
            payload.update(self._build_perplexity_params(**kwargs))
        else:
            # å…¶ä»–æœç´¢å¼•æ“çš„é€šç”¨å‚æ•°
            payload.update(kwargs)
        
        return await self._make_api_call(config, payload)
    
    def _build_perplexity_params(self, **kwargs) -> Dict[str, Any]:
        """æ„å»ºPerplexityç‰¹æœ‰å‚æ•°"""
        perplexity_params = {}
        
        # æ—¶é—´è¿‡æ»¤å‚æ•°
        if "search_recency_filter" in kwargs:
            perplexity_params["search_recency_filter"] = kwargs["search_recency_filter"]
        elif "time_filter" in kwargs:
            # å…¼å®¹æ—§çš„time_filterå‚æ•°å
            perplexity_params["search_recency_filter"] = kwargs["time_filter"]
        
        # åŸŸåè¿‡æ»¤åŠŸèƒ½å·²ç§»é™¤ - é€šè¿‡promptå¼•å¯¼AIæœç´¢æƒå¨æ¥æº
        
        # ç›¸å…³é—®é¢˜å‚æ•°
        if "return_related_questions" in kwargs:
            perplexity_params["return_related_questions"] = kwargs["return_related_questions"]
        
        # Webæœç´¢é€‰é¡¹
        if "web_search_options" in kwargs:
            perplexity_params["web_search_options"] = kwargs["web_search_options"]
        elif "search_context_size" in kwargs:
            perplexity_params["web_search_options"] = {
                "search_context_size": kwargs["search_context_size"]
            }
        
        # æ—¥æœŸèŒƒå›´è¿‡æ»¤
        if "search_after_date_filter" in kwargs:
            perplexity_params["search_after_date_filter"] = kwargs["search_after_date_filter"]
        
        if "search_before_date_filter" in kwargs:
            perplexity_params["search_before_date_filter"] = kwargs["search_before_date_filter"]
        
        # å›¾ç‰‡è¿”å›
        if "return_images" in kwargs:
            perplexity_params["return_images"] = kwargs["return_images"]
        
        # æœ€å¤§ç»“æœæ•°é‡
        if "max_results" in kwargs:
            perplexity_params["max_tokens"] = kwargs.get("max_tokens", 4000)
        
        # å…¶ä»–é€šç”¨å‚æ•°
        for param in ["temperature", "max_tokens", "top_p"]:
            if param in kwargs:
                perplexity_params[param] = kwargs[param]
        
        return perplexity_params
    
    async def _make_api_call(self, config: ModelConfig, payload: Dict) -> Dict[str, Any]:
        """æ‰§è¡ŒAPIè°ƒç”¨ - æ”¯æŒå¼‚æ­¥HTTPå®¢æˆ·ç«¯"""
        self.usage_stats[config.alias]["calls"] += 1
        
        try:
            # æ„å»ºè¯·æ±‚å¤´
            headers = {
                "Authorization": f"Bearer {config.api_key}",
                "Content-Type": "application/json"
            }
            headers.update(config.headers)
            
            # ä¼˜å…ˆä½¿ç”¨å¼‚æ­¥HTTPå®¢æˆ·ç«¯
            if HTTPX_AVAILABLE:
                return await self._make_async_request(config, payload, headers)
            else:
                # é™çº§åˆ°åŒæ­¥è¯·æ±‚ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
                return await self._make_sync_request(config, payload, headers)
                
        except Exception as e:
            self.usage_stats[config.alias]["errors"] += 1
            error_msg = f"APIè°ƒç”¨å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            return {"success": False, "error": error_msg}
    
    async def _make_async_request(self, config: ModelConfig, payload: Dict, headers: Dict) -> Dict[str, Any]:
        """ä½¿ç”¨httpxæ‰§è¡Œå¼‚æ­¥APIè°ƒç”¨"""
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                config.base_url,
                json=payload,
                headers=headers
            )
            
            if response.status_code == 200:
                result = response.json()
                
                # æ›´æ–°ç»Ÿè®¡
                self.usage_stats[config.alias]["success"] += 1
                self.usage_stats[config.alias]["last_used"] = datetime.now().isoformat()
                
                # ç»Ÿè®¡tokenä½¿ç”¨
                if "usage" in result:
                    usage = result["usage"]
                    self.token_usage[config.alias]["input_tokens"] += usage.get("prompt_tokens", 0)
                    self.token_usage[config.alias]["output_tokens"] += usage.get("completion_tokens", 0)
                    self.token_usage[config.alias]["total_tokens"] += usage.get("total_tokens", 0)
                
                # å¤„ç†ä¸åŒæä¾›å•†çš„å“åº”æ ¼å¼
                return self._process_response(config, result)
            else:
                raise Exception(f"HTTP {response.status_code}: {response.text}")
    
    async def _make_sync_request(self, config: ModelConfig, payload: Dict, headers: Dict) -> Dict[str, Any]:
        """åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è¯·æ±‚"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self._sync_request_impl, config, payload, headers)
    
    def _sync_request_impl(self, config: ModelConfig, payload: Dict, headers: Dict) -> Dict[str, Any]:
        """åŒæ­¥è¯·æ±‚çš„å®é™…å®ç°"""
        request_data = json.dumps(payload).encode('utf-8')
        req = urllib.request.Request(
            config.base_url,
            data=request_data,
            headers=headers
        )
        
        with urllib.request.urlopen(req, timeout=120) as response:
            if response.status == 200:
                result_data = response.read().decode('utf-8')
                result = json.loads(result_data)
                
                # æ›´æ–°ç»Ÿè®¡
                self.usage_stats[config.alias]["success"] += 1
                self.usage_stats[config.alias]["last_used"] = datetime.now().isoformat()
                
                # ç»Ÿè®¡tokenä½¿ç”¨
                if "usage" in result:
                    usage = result["usage"]
                    self.token_usage[config.alias]["input_tokens"] += usage.get("prompt_tokens", 0)
                    self.token_usage[config.alias]["output_tokens"] += usage.get("completion_tokens", 0)
                    self.token_usage[config.alias]["total_tokens"] += usage.get("total_tokens", 0)
                
                # å¤„ç†ä¸åŒæä¾›å•†çš„å“åº”æ ¼å¼
                return self._process_response(config, result)
            else:
                error_text = response.read().decode('utf-8')
                raise Exception(f"APIé”™è¯¯ {response.status}: {error_text}")
    
    def _process_response(self, config: ModelConfig, result: Dict) -> Dict[str, Any]:
        """å¤„ç†ä¸åŒæä¾›å•†çš„å“åº”æ ¼å¼"""
        if config.provider == "perplexity":
            # æ ‡å‡†åŒ–Perplexityå“åº”
            content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
            search_results = result.get("search_results", [])
            related_questions = result.get("related_questions", [])
            
            return {
                "success": True,
                "content": content,
                "search_results": search_results,
                "related_questions": related_questions,
                "usage": result.get("usage", {}),
                "model": config.model_id,
                "provider": config.provider,
                "results": search_results  # å…¼å®¹æ€§å­—æ®µ
            }
        
        # å…¶ä»–æ¨¡å‹çš„æ ‡å‡†å“åº”
        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
        return {
            "success": True,
            "content": content,
            "usage": result.get("usage", {}),
            "model": config.model_id,
            "provider": config.provider
        }
                if response.status == 200:
                    result_data = response.read().decode('utf-8')
                    result = json.loads(result_data)
                    
                    # æ›´æ–°ç»Ÿè®¡
                    self.usage_stats[config.alias]["success"] += 1
                    self.usage_stats[config.alias]["last_used"] = datetime.now().isoformat()
                    
                    # ç»Ÿè®¡tokenä½¿ç”¨ï¼ˆå¦‚æœAPIè¿”å›äº†usageä¿¡æ¯ï¼‰
                    if "usage" in result:
                        usage = result["usage"]
                        self.token_usage[config.alias]["input_tokens"] += usage.get("prompt_tokens", 0)
                        self.token_usage[config.alias]["output_tokens"] += usage.get("completion_tokens", 0)
                        self.token_usage[config.alias]["total_tokens"] += usage.get("total_tokens", 0)
                    
                    # å¤„ç†Perplexityç‰¹å®šçš„å“åº”æ ¼å¼
                    if config.provider == "perplexity":
                        # æ ‡å‡†åŒ–Perplexityå“åº”
                        content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                        search_results = result.get("search_results", [])
                        related_questions = result.get("related_questions", [])
                        
                        return {
                            "success": True,
                            "content": content,
                            "search_results": search_results,
                            "related_questions": related_questions,
                            "usage": result.get("usage", {}),
                            "model": config.model_id,
                            "provider": config.provider,
                            "results": search_results  # å…¼å®¹æ€§å­—æ®µ
                        }
                    
                    # å…¶ä»–æ¨¡å‹çš„æ ‡å‡†å“åº”
                    content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                    return {
                        "success": True,
                        "content": content,
                        "usage": result.get("usage", {}),
                        "model": config.model_id,
                        "provider": config.provider
                    }
                else:
                    error_text = response.read().decode('utf-8')
                    raise Exception(f"APIé”™è¯¯ {response.status}: {error_text}")
                    
        except Exception as e:
            self.usage_stats[config.alias]["errors"] += 1
            print(f"âŒ {config.alias} APIè°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def switch_model(self, model_type: ModelType, new_alias: str) -> bool:
        """åˆ‡æ¢æŒ‡å®šç±»å‹çš„ä¸»è¦æ¨¡å‹"""
        new_config = self.get_model(new_alias)
        if not new_config or new_config.model_type != model_type:
            return False
            
        # æ›´æ–°ä¸»è¦æ¨¡å‹åˆ«å
        type_name = model_type.value
        if type_name in self.models:
            old_config = self.models[type_name]
            print(f"ğŸ”„ åˆ‡æ¢{type_name}æ¨¡å‹: {old_config.provider}-{old_config.model_id} â†’ {new_config.provider}-{new_config.model_id}")
        
        self.models[type_name] = new_config
        return True
    
    def get_model_status(self) -> Dict[str, Dict]:
        """è·å–æ‰€æœ‰æ¨¡å‹çŠ¶æ€"""
        status = {}
        for alias, config in self.models.items():
            stats = self.usage_stats[alias]
            tokens = self.token_usage[alias]
            
            status[alias] = {
                "provider": config.provider,
                "model_id": config.model_id,
                "type": config.model_type.value,
                "available": bool(config.api_key),
                "stats": stats,
                "token_usage": tokens
            }
        return status
    
    def log_token_usage(self, model_alias: str, input_tokens: int, output_tokens: int = 0):
        """è®°å½•tokenä½¿ç”¨æƒ…å†µ"""
        if model_alias in self.token_usage:
            self.token_usage[model_alias]["input_tokens"] += input_tokens
            self.token_usage[model_alias]["output_tokens"] += output_tokens
            self.token_usage[model_alias]["total_tokens"] += (input_tokens + output_tokens)


# ğŸŒŸ å…¨å±€å•ä¾‹å®ä¾‹
model_manager = UnifiedModelManager()


# ğŸ¯ ç®€åŒ–çš„APIæ¥å£ - ä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
async def call_llm(prompt: str, **kwargs) -> Dict[str, Any]:
    """è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹"""
    return await model_manager.call_llm(prompt, **kwargs)


async def call_embedding(texts: List[str], **kwargs) -> Dict[str, Any]:
    """è°ƒç”¨å‘é‡åŒ–æ¨¡å‹"""
    return await model_manager.call_embedding(texts, **kwargs)


async def call_search(query: str, model_alias: str = "search", **kwargs) -> Dict[str, Any]:
    """è°ƒç”¨æœç´¢æ¨¡å‹"""
    return await model_manager.call_search(query, model_alias, **kwargs)


def log_tokens(model_alias: str, input_tokens: int, output_tokens: int = 0):
    """è®°å½•tokenä½¿ç”¨"""
    model_manager.log_token_usage(model_alias, input_tokens, output_tokens)


def get_model_status() -> Dict[str, Dict]:
    """è·å–æ¨¡å‹çŠ¶æ€"""
    return model_manager.get_model_status()


def switch_primary_model(model_type: str, new_alias: str) -> bool:
    """åˆ‡æ¢ä¸»è¦æ¨¡å‹"""
    type_enum = ModelType(model_type)
    return model_manager.switch_model(type_enum, new_alias)


if __name__ == "__main__":
    """æµ‹è¯•å’Œæ¼”ç¤º"""
    print("ğŸ¯ ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨æ¼”ç¤º")
    print("=" * 40)
    
    # æ˜¾ç¤ºå·²æ³¨å†Œçš„æ¨¡å‹
    print("ğŸ“Š å·²æ³¨å†Œæ¨¡å‹:")
    for alias, config in model_manager.models.items():
        print(f"  â€¢ {alias}: {config.provider}-{config.model_id} ({config.model_type.value})")
    
    print(f"\nğŸ” LLMæ¨¡å‹: {len(model_manager.get_models_by_type(ModelType.LLM))}")
    print(f"ğŸ§  å‘é‡åŒ–æ¨¡å‹: {len(model_manager.get_models_by_type(ModelType.EMBEDDING))}")
    print(f"ğŸ” æœç´¢æ¨¡å‹: {len(model_manager.get_models_by_type(ModelType.SEARCH))}")
    
    print("\nâœ… ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼")
    print("ç°åœ¨æ‰€æœ‰æ¨¡å‹è°ƒç”¨éƒ½é€šè¿‡è¿™ä¸ªç»Ÿä¸€æ¥å£ ğŸ‰")