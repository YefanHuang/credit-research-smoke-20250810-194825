#!/usr/bin/env python3
"""
æ¨¡å‹ä½¿ç”¨ç¤ºä¾‹ - å±•ç¤ºæ–°çš„é¢å‘å¯¹è±¡è®¾è®¡å¦‚ä½•è½»æ¾æ‰©å±•å’Œä½¿ç”¨å¤šç§æ¨¡å‹
"""

import asyncio
from config import APIConfig, ModelConfig
from model_manager import ModelType

async def demo_new_model_system():
    """æ¼”ç¤ºæ–°çš„æ¨¡å‹é…ç½®ç³»ç»Ÿ"""
    
    print("ğŸš€ æ–°çš„é¢å‘å¯¹è±¡æ¨¡å‹é…ç½®ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # 1. åˆå§‹åŒ–é…ç½® - è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰å¯ç”¨æ¨¡å‹
    config = APIConfig()
    
    print("ğŸ“Š å½“å‰å¯ç”¨çš„æ¨¡å‹:")
    for alias, model_config in config.model_registry.models.items():
        print(f"  â€¢ {alias}: {model_config.provider} - {model_config.model_id} ({model_config.model_type})")
    
    print("\nğŸ” åƒé—®ç³»åˆ—æ¨¡å‹:")
    qwen_models = config.model_registry.get_models_by_provider("qwen")
    for alias, model_config in qwen_models.items():
        print(f"  â€¢ {alias}: {model_config.model_id} - æœ€å¤§tokens: {model_config.max_tokens}")
    
    print("\nğŸ¯ å‘é‡åŒ–æ¨¡å‹:")
    embedding_models = config.model_registry.get_models_by_type("embedding")
    for alias, model_config in embedding_models.items():
        print(f"  â€¢ {alias}: {model_config.provider} - {model_config.model_id}")
    
    # 2. æ¼”ç¤ºåŠ¨æ€æ¨¡å‹æ³¨å†Œ
    print("\nâ• åŠ¨æ€æ·»åŠ æ–°æ¨¡å‹:")
    
    # æ·»åŠ ä¸€ä¸ªè‡ªå®šä¹‰åƒé—®æ¨¡å‹
    custom_qwen = ModelConfig(
        provider="qwen",
        model_id="qwen-14b-chat",
        model_type="chat",
        api_key=config.model_registry.get_model("qwen-turbo").api_key,  # å¤ç”¨APIå¯†é’¥
        base_url="https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation",
        max_tokens=32000,
        temperature=0.3
    )
    config.model_registry.register_model("qwen-14b", custom_qwen)
    print(f"  âœ… æ·»åŠ äº†è‡ªå®šä¹‰æ¨¡å‹: qwen-14b")
    
    # æ·»åŠ ä¸€ä¸ªClaudeæ¨¡å‹ï¼ˆå¦‚æœæœ‰APIå¯†é’¥ï¼‰
    import os
    if os.getenv('CLAUDE_API_KEY'):
        claude_model = ModelConfig(
            provider="claude",
            model_id="claude-3-opus-20240229",
            model_type="chat",
            api_key=os.getenv('CLAUDE_API_KEY'),
            base_url="https://api.anthropic.com/v1/messages",
            max_tokens=4000,
            custom_headers={"anthropic-version": "2023-06-01"}
        )
        config.model_registry.register_model("claude-opus", claude_model)
        print(f"  âœ… æ·»åŠ äº†Claudeæ¨¡å‹: claude-opus")
    
    print(f"\nğŸ“ˆ ç°åœ¨æ€»å…±æœ‰ {len(config.model_registry.models)} ä¸ªæ¨¡å‹å¯ç”¨")
    
    # 3. æ¼”ç¤ºæ¨¡å‹ä½¿ç”¨
    from model_manager import model_manager, call_llm, call_embedding
    
    if any(model.api_key for model in config.model_registry.models.values()):
        print("\nğŸ”§ ä½¿ç”¨ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨...")
        
        # æ˜¾ç¤ºå½“å‰å¯ç”¨æ¨¡å‹
        llm_models = model_manager.get_models_by_type(ModelType.LLM)
        embedding_models = model_manager.get_models_by_type(ModelType.EMBEDDING)
        
        print(f"  â€¢ å¯ç”¨LLMæ¨¡å‹: {len(llm_models)}")
        print(f"  â€¢ å¯ç”¨å‘é‡åŒ–æ¨¡å‹: {len(embedding_models)}")
        
        # æ¼”ç¤ºæ¨¡å‹åˆ‡æ¢
        if len(llm_models) > 1:
            print("\nğŸ”„ æ¨¡å‹åˆ‡æ¢æ¼”ç¤º:")
            aliases = list(llm_models.keys())
            print(f"  å¯ç”¨çš„LLMæ¨¡å‹: {', '.join(aliases)}")
            
            if "llm-claude" in aliases:
                success = model_manager.switch_model(ModelType.LLM, "llm-claude")
                if success:
                    print(f"  âœ… æˆåŠŸåˆ‡æ¢åˆ°Claudeæ¨¡å‹")
        
        # æ¼”ç¤ºå‘é‡åŒ–ï¼ˆå¦‚æœæœ‰å¯ç”¨çš„æ¨¡å‹ï¼‰
        if embedding_models:
            print(f"\nğŸ§  å‘é‡åŒ–æ¼”ç¤º:")
            try:
                # ä½¿ç”¨ç»Ÿä¸€æ¥å£
                result = await call_embedding(["æµ‹è¯•æ–‡æœ¬"])
                print(f"  âœ… ä½¿ç”¨ç»Ÿä¸€æ¨¡å‹ç®¡ç†å™¨æˆåŠŸç”Ÿæˆå‘é‡")
                print(f"  ğŸ“Š å‘é‡ç»´åº¦: {len(result['embeddings'][0]) if result['embeddings'] else 'æœªçŸ¥'}")
            except Exception as e:
                print(f"  âŒ å‘é‡åŒ–å¤±è´¥: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼æ–°ç³»ç»Ÿçš„ä¼˜åŠ¿:")
    print("  â€¢ âœ… æ”¯æŒå¤šç§åƒé—®æ¨¡å‹ (turbo, plus, max)")
    print("  â€¢ âœ… åŠ¨æ€æ¨¡å‹æ³¨å†Œï¼Œæ— éœ€ä¿®æ”¹ä»£ç ")
    print("  â€¢ âœ… ç»Ÿä¸€çš„æ¥å£ï¼Œåˆ‡æ¢æ¨¡å‹é›¶æˆæœ¬")
    print("  â€¢ âœ… å®Œå…¨å‘åå…¼å®¹ç°æœ‰åŠŸèƒ½")
    print("  â€¢ âœ… é¢å‘å¯¹è±¡è®¾è®¡ï¼Œæ˜“äºæ‰©å±•")

def demo_easy_model_addition():
    """æ¼”ç¤ºæ·»åŠ æ–°æ¨¡å‹æœ‰å¤šå®¹æ˜“"""
    
    print("\nğŸ”¥ æ·»åŠ æ–°æ¨¡å‹æ¼”ç¤º - 5æ­¥æ³•")
    print("=" * 40)
    
    print("æ­¥éª¤1ï¸âƒ£: æ·»åŠ APIå¯†é’¥åˆ°ç¯å¢ƒå˜é‡")
    print("  export NEW_MODEL_API_KEY=your_key_here")
    
    print("\næ­¥éª¤2ï¸âƒ£: æ³¨å†Œæ–°æ¨¡å‹ (ä¸€è¡Œä»£ç )")
    print("""
    config.model_registry.register_model("new-model", ModelConfig(
        provider="new_provider",
        model_id="new-model-v1", 
        model_type="chat",
        api_key=os.getenv('NEW_MODEL_API_KEY'),
        base_url="https://api.newprovider.com/v1/chat"
    ))
    """)
    
    print("æ­¥éª¤3ï¸âƒ£: ç«‹å³å¯ç”¨ï¼Œæ— éœ€é‡å¯")
    print("  api_manager.current_chat_model = 'new-model'")
    
    print("\næ­¥éª¤4ï¸âƒ£: å¦‚æœéœ€è¦ç‰¹æ®ŠAPIæ ¼å¼ï¼Œåœ¨_call_embedding_apiæ·»åŠ ä¸€ä¸ªelif")
    print("æ­¥éª¤5ï¸âƒ£: å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰")
    
    print("\nå¯¹æ¯”ä¹‹å‰éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:")
    print("  âŒ ä¹‹å‰: 20+ ä¸ªæ–‡ä»¶ï¼Œ4ä¸ªä¸åŒå±‚é¢")
    print("  âœ… ç°åœ¨: 1-2 ä¸ªæ–‡ä»¶ï¼Œçº¯æ‰©å±•æ— ä¿®æ”¹")

if __name__ == "__main__":
    print("ğŸ¤– Credit Monitor - æ¨¡å‹é…ç½®ç³»ç»Ÿæ¼”ç¤º")
    
    asyncio.run(demo_new_model_system())
    demo_easy_model_addition()